/**************Hadoop In Real World**************/
Hadoop In Real World *** http://www.hadoopinrealworld.com
HDFS - Working With HDFS
/**************Hadoop In Real World**************/

### LOCAL FILE SYSTEM ###

	ls
	mkdir
	cp
	mv
	rm

### LISTING ROOT DIRECTORY ###

hadoop fs -ls /

### LISTING DEFAULT TO HOME DIRECTORY ###

hadoop fs -ls

hadoop fs -ls /user/hirwuser150430

### CREATE A DIRECTORY IN HDFS ###

hadoop fs -mkdir hadoop-test1

### COPY FROM LOCAL FS TO HDFS ###

hadoop fs -copyFromLocal  /hirw-starterkit/hdfs/commands/dwp-payments-april10.csv hadoop-test1

### COPY TO HDFS TO LOCAL FS ###

hadoop fs -copyToLocal hadoop-test1/dwp-payments-april10.csv .

hadoop fs -ls hadoop-test1

### CREATE 2 MORE DIRECTORIES ###

hadoop fs -mkdir hadoop-test2

hadoop fs -mkdir hadoop-test3

### COPY A FILE FROM ONE FOLDER TO ANOTHER ###

hadoop fs -cp hadoop-test1/dwp-payments-april10.csv hadoop-test2

### MOVE A FILE FROM ONE FOLDER TO ANOTHER ###

hadoop fs -mv hadoop-test1/dwp-payments-april10.csv hadoop-test3

### CHECK REPLICATION ###(Replication factor is set 3 by default)

hadoop fs -ls hadoop-test3

### CHANGE OR SET REPLICATION FACTOR ###

hadoop fs -Ddfs.replication=2 -cp hadoop-test2/dwp-payments-april10.csv hadoop-test2/test_with_rep2.csv

hadoop fs -ls hadoop-test2

hadoop fs -ls hadoop-test2/test_with_rep2.csv

### CHANGING PERMISSIONS ###

hadoop fs -chmod 777 hadoop-test2/test_with_rep2.csv

### FILE SYSTEM CHECK - REQUIRES ADMIN PREVILEGES ###( the file blocks are physically stored in sites defined in hdfs-site.xml in the dfs.datanode.dir tag.
 the local file system can only see the blocks but hdfs can conctruct them. Each datanode knows which files it is reponsible for but it does not know that which blocks belong to which dataset.
the namenode keeps track of all key information which provodes a global view of the dataset and even the metadata. It just doesnt know the datanode locations.When the nodes start up the datanodes 
connect up with the namenodes and broadcast the list of blocks each datanode is reponsible for. Namenode will hold the block locations in memory and never persist them because in a busy cluster
a hdfs is constantly changing with new data files coming into the cluster. IF namenode has to persist by writing every change to the block it would bottleneck, so the namenode holds block locations
just in memory. )

sudo -u hdfs hdfs fsck /user/hirwuser150430/hadoop-test2 -files -blocks -locations 

sudo -u hdfs hdfs fsck /user/hirwuser150430/hadoop-test3 -files -blocks -locations 

sudo -u hdfs hdfs fsck /user/ubuntu/input/yelp/yelp_academic_dataset_review.json -files -blocks -locations 

vi /etc/hadoop/conf/hdfs-site.xml

/data/1/dfs/dn/current/BP-2125152513-172.31.45.216-1410037307133/current/finalized

### DELETE DIR/FILES IN HDFS ###

hadoop fs -rm hadoop-test2/test_with_rep5.csv

hadoop fs -rm -r hadoop-test1
hadoop fs -rm -r hadoop-test2
hadoop fs -rm -r hadoop-test3